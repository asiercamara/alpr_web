[![en](https://img.shields.io/badge/lang-en-red.svg)](./README.md)
[![es](https://img.shields.io/badge/lang-es-yellow.svg)](./README.es.md)

# Web ALPR - Reconocimiento AutomÃ¡tico de MatrÃ­culas en Navegador

Este proyecto implementa un sistema de reconocimiento automÃ¡tico de matrÃ­culas de vehÃ­culos (ALPR - Automatic License Plate Recognition) que funciona completamente en el navegador, sin necesidad de servidores externos. Utiliza modelos de IA optimizados (YOLO y OCR) que se ejecutan localmente mediante WebAssembly.

## CaracterÃ­sticas

- ğŸ” DetecciÃ³n de matrÃ­culas en tiempo real
- ğŸ“· Funciona con imÃ¡genes, videos y cÃ¡mara web
- ğŸ§  Modelos de IA optimizados para navegador (ONNX)
- ğŸŒ Funciona completamente offline
- ğŸŒ™ Modo oscuro/claro
- ğŸ“± DiseÃ±o responsive para dispositivos mÃ³viles
- âš¡ Rendimiento optimizado con Web Workers

## Requisitos

- Node.js 16.x o superior
- NPM 8.x o superior
- Navegador moderno con soporte para WebAssembly

## InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/web_alpr.git
cd web_alpr

# Instalar dependencias
npm install
```

## Uso

### Desarrollo

Para iniciar el servidor de desarrollo:

```bash
npm run dev
```

Esto abrirÃ¡ automÃ¡ticamente la aplicaciÃ³n en tu navegador predeterminado. Por defecto, la aplicaciÃ³n estarÃ¡ disponible en: http://localhost:5173/

### CompilaciÃ³n para producciÃ³n

```bash
npm run build
```

Esto generarÃ¡ una versiÃ³n optimizada de la aplicaciÃ³n en la carpeta `dist/` que puede ser desplegada en cualquier servidor web estÃ¡tico.

### Vista previa de la versiÃ³n de producciÃ³n

```bash
npm run preview
```

## Estructura del Proyecto

```bash
web_alpr/
â”œâ”€â”€ index.html              # PÃ¡gina HTML principal
â”œâ”€â”€ package.json            # Dependencias y scripts
â”œâ”€â”€ public/                 # Archivos estÃ¡ticos
â”‚   â”œâ”€â”€ favicon.ico         # Favicon
â”‚   â””â”€â”€ models/             # Modelos ONNX pre-entrenados
â”‚       â”œâ”€â”€ european_mobile_vit_v2_ocr_config.yaml
â”‚       â”œâ”€â”€ european_mobile_vit_v2_ocr.onnx
â”‚       â””â”€â”€ yolo-v9-t-384-license-plates-end2end.onnx
â”œâ”€â”€ src/                    # CÃ³digo fuente
â”‚   â”œâ”€â”€ object_detector.js  # Punto de entrada principal
â”‚   â”œâ”€â”€ tailwind.css        # Estilos CSS con Tailwind
â”‚   â”œâ”€â”€ models/             # Configuraciones de modelos
â”‚   â”‚   â””â”€â”€ european_mobile_vit_v2_ocr_config.json
â”‚   â”œâ”€â”€ modules/            # MÃ³dulos funcionales parte web
â”‚   â”‚   â”œâ”€â”€ config.js       # ConfiguraciÃ³n global
â”‚   â”‚   â”œâ”€â”€ detector.js     # GestiÃ³n de detecciÃ³n
â”‚   â”‚   â”œâ”€â”€ media.js        # Manejo de medios (imagen/video/cÃ¡mara)
â”‚   â”‚   â”œâ”€â”€ modal.js        # Gestor de ventanas modales
â”‚   â”‚   â”œâ”€â”€ plateStorage.js # Almacenamiento de matrÃ­culas detectadas
â”‚   â”‚   â”œâ”€â”€ ui.js           # Funciones de interfaz de usuario
â”‚   â”‚   â””â”€â”€ validation.js   # ValidaciÃ³n de datos
â”‚   â””â”€â”€ worker/             # Web Workers para procesamiento en segundo plano
â”‚       â”œâ”€â”€ mainWorker.js   # Worker principal
â”‚       â”œâ”€â”€ modelsLoader.js # Cargador de modelos
â”‚       â”œâ”€â”€ detector/       # MÃ³dulos para detecciÃ³n de matrÃ­culas
â”‚       â”‚   â”œâ”€â”€ boundingBoxUtils.js # Utilidades para cuadros delimitadores
â”‚       â”‚   â”œâ”€â”€ detectionProcessor.js # Procesador de detecciones
â”‚       â”‚   â””â”€â”€ imageProcessor.js # Procesador de imÃ¡genes para detecciÃ³n
â”‚       â””â”€â”€ ocr/            # MÃ³dulos para reconocimiento de texto
â”‚           â”œâ”€â”€ imageProcessor.js # Procesador de imÃ¡genes para OCR
â”‚           â”œâ”€â”€ ocrProcessor.js # Procesador principal de OCR
â”‚           â””â”€â”€ textProcessor.js # Procesador de texto reconocido
â””â”€â”€ test/                   # ImÃ¡genes y videos de prueba
```

## Arquitectura y Componentes

### Flujo de Procesamiento

1. **Captura de Imagen**: A travÃ©s de foto, video o cÃ¡mara web
2. **DetecciÃ³n de MatrÃ­culas**: Usando YOLOv9 para identificar y localizar matrÃ­culas
3. **ExtracciÃ³n de Regiones**: Recorte de las Ã¡reas detectadas como matrÃ­culas
4. **OCR**: Reconocimiento del texto en las regiones extraÃ­das
5. **VisualizaciÃ³n**: Muestra los resultados en la interfaz

### Componentes Principales

#### 1. Detector de MatrÃ­culas

Utiliza un modelo YOLOv9 optimizado para detectar matrÃ­culas en imÃ¡genes. El modelo estÃ¡ entrenado especÃ­ficamente para reconocer placas de matrÃ­cula en diferentes condiciones.

#### 2. Sistema OCR

Implementa un modelo de reconocimiento Ã³ptico de caracteres basado en MobileViT v2, optimizado para leer texto de matrÃ­culas europeas.

#### 3. Web Workers

Los modelos de IA se ejecutan en Web Workers para evitar bloquear el hilo principal del navegador, proporcionando una experiencia de usuario fluida.

#### 4. Interfaz de Usuario

Interfaz moderna y responsive construida con Tailwind CSS 4.0, con soporte para modo oscuro/claro y optimizada para diferentes dispositivos.

## Modelos Utilizados

### Detector de MatrÃ­culas

- **Modelo**: yolo-v9-t-384-license-plates-end2end.onnx [open-image-models](https://github.com/ankandrew/open-image-models)
- **Formato**: ONNX
- **ResoluciÃ³n de entrada**: 1x1 
- **Clases**: Detecta especÃ­ficamente matrÃ­culas de vehÃ­culos

#### Arquitectura YOLO (You Only Look Once)

YOLO es un algoritmo de detecciÃ³n de objetos en tiempo real que aplica una Ãºnica red neuronal a la imagen completa. Esta red divide la imagen en regiones y predice cuadros delimitadores y probabilidades para cada regiÃ³n. Los cuadros delimitadores se ponderan por las probabilidades predichas.

CaracterÃ­sticas principales de YOLOv9:
- **DetecciÃ³n en una sola pasada**: A diferencia de los sistemas de dos etapas, YOLO analiza toda la imagen en una sola pasada, lo que lo hace extremadamente rÃ¡pido.
- **Arquitectura optimizada**: YOLOv9 es una versiÃ³n reducida diseÃ±ada para ejecutarse en dispositivos con recursos limitados, ideal para aplicaciones web.
- **Alta precisiÃ³n**: A pesar de su tamaÃ±o reducido, el modelo alcanza un equilibrio Ã³ptimo entre velocidad y precisiÃ³n para la detecciÃ³n de matrÃ­culas.
- **RepresentaciÃ³n espacial**: El modelo divide la imagen en una cuadrÃ­cula y predice mÃºltiples cuadros delimitadores y puntuaciones de confianza para cada celda.

El modelo usado en este proyecto ha sido especÃ­ficamente entrenado y optimizado para detectar matrÃ­culas vehiculares en diferentes condiciones de iluminaciÃ³n y Ã¡ngulos.

### OCR de MatrÃ­culas

- **Modelo**: european_mobile_vit_v2_ocr.onnx [open-image-models](https://github.com/ankandrew/open-image-models)
- **Formato**: ONNX
- **ResoluciÃ³n de entrada**: european_mobile_vit_v2_ocr_config.json - 140x70 pÃ­xeles
- **Alfabeto**: Caracteres alfanumÃ©ricos (0-9, A-Z) y guiÃ³n

#### Arquitectura ConvNet (CNN)

La arquitectura del modelo OCR es simple pero efectiva, consistiendo en varias capas CNN con mÃºltiples cabezas de salida. Cada cabeza representa la predicciÃ³n de un carÃ¡cter de la matrÃ­cula. 

Si la matrÃ­cula consiste en un mÃ¡ximo de 7 caracteres (`max_plate_slots=7`), entonces el modelo tendrÃ­a 7 cabezas de salida. Cada cabeza genera una distribuciÃ³n de probabilidad sobre el vocabulario especificado durante el entrenamiento. Por lo tanto, la predicciÃ³n de salida para una sola matrÃ­cula tendrÃ¡ una forma de `(max_plate_slots, vocabulary_size)`.

![Modelo de cabezas OCR](https://raw.githubusercontent.com/ankandrew/fast-plate-ocr/4a7dd34c9803caada0dc50a33b59487b63dd4754/extra/FCN.png)

#### MÃ©tricas del Modelo OCR

Durante el entrenamiento, el modelo utiliza las siguientes mÃ©tricas:

* **plate_acc**: Calcula el nÃºmero de **matrÃ­culas** que fueron **completamente clasificadas** correctamente. Para una matrÃ­cula individual, si la verdad fundamental es `ABC123` y la predicciÃ³n tambiÃ©n es `ABC123`, puntuarÃ­a 1. Sin embargo, si la predicciÃ³n fuera `ABD123`, puntuarÃ­a 0, ya que **no todos los caracteres** fueron correctamente clasificados.

* **cat_acc**: Calcula la precisiÃ³n de **caracteres individuales** dentro de las matrÃ­culas. Por ejemplo, si la etiqueta correcta es `ABC123` y la predicciÃ³n es `ABC133`, producirÃ­a una precisiÃ³n del 83.3% (5 de 6 caracteres clasificados correctamente), en lugar de 0% como en plate_acc.

* **top_3_k**: Calcula con quÃ© frecuencia el carÃ¡cter verdadero estÃ¡ incluido en las **3 predicciones principales** (las tres predicciones con mayor probabilidad).

En esta implementaciÃ³n web, el modelo ha sido convertido a formato ONNX para optimizar su rendimiento en el navegador, manteniendo un equilibrio entre precisiÃ³n y velocidad de procesamiento.

## ConfiguraciÃ³n Avanzada

### Modificar Umbrales de DetecciÃ³n

Los umbrales de confianza para la detecciÃ³n y el OCR pueden ajustarse en los archivos:

- `src/worker/detector/detectionProcessor.js` - Para el umbral de detecciÃ³n
- `src/modules/detector.js` - Para el umbral de visualizaciÃ³n

```javascript
// Umbral de confianza para detecciÃ³n
const confThresh = 0.6; // Modificar segÃºn necesidad
```

### PersonalizaciÃ³n de la Interfaz

El proyecto utiliza Tailwind CSS 4.0, que puede personalizarse modificando el archivo `src/tailwind.css` o el tema en el HTML.

## Limitaciones

- El rendimiento depende de la capacidad de procesamiento del dispositivo
- Los modelos estÃ¡n optimizados para matrÃ­culas europeas
- No funciona en navegadores antiguos sin soporte para WebAssembly

## Reconocimientos

- [fast-alpr](https://github.com/ankandrew/fast-alpr) - Basado en este proyecto
  - [fast-plate-ocr](https://github.com/ankandrew/fast-plate-ocr) - Modelos de **OCR** por defecto
  - [open-image-models](https://github.com/ankandrew/open-image-models) - Modelos de **detecciÃ³n** de placas por defecto

## Uso de Inteligencia Artificial

Este proyecto ha hecho uso extensivo de inteligencia artificial, principalmente para:

- Conversiones de Python a JavaScript
- Desarrollo de la interfaz web y funcionalidades del cliente

Las herramientas y modelos de IA utilizados incluyen:

- [roocode](https://docs.roocode.com/) con OpenRouter y Claude 3.7 Sonnet (normal y thinking)
- [GitHub Copilot](https://github.com/features/copilot) con los mismos modelos anteriores
- Otras plataformas como [Claude](https://claude.ai), [ChatGPT](https://chat.openai.com) y [Google Gemini](https://gemini.google.com)
